{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2089687f",
   "metadata": {},
   "source": [
    "# Introduction to Data Processing with Pandas\n",
    "\n",
    "Pandas is one of the most powerful and widely-used Python libraries for working with structured data. It provides fast, flexible, and intuitive tools to load, explore, clean, transform, and analyze data — especially tabular data like spreadsheets or CSV files. Whether you're handling messy survey results, merging data from multiple sources, or preparing data for machine learning, pandas offers a robust foundation for data wrangling and analysis in Python. Its syntax is readable and expressive, making it ideal for both beginners and professionals.\n",
    "\n",
    "This notebook introduces the fundamentals of working with tabular data using the pandas library.\n",
    "\n",
    "## Learning Outcomes\n",
    "By the end of this tutorial, participants will be able to:\n",
    "### Understanda pandas core data structures\n",
    " - Dataframes and Series\n",
    " - Create Dataframes and Series from other Python data structures (e.g., lists)\n",
    "### Load and Explore Data\n",
    "- Load and Explore Data from different sources\n",
    "- Understand data structure using ```.head(), .info(), .describe()```\n",
    "### Preprocess Data\n",
    " - Identify and handle missing values using isna(), fillna(), dropna()\n",
    " - Convert data types using ```.astype()``` and ```to_datetime()```\n",
    " - Rename and reorder columns\n",
    "### Transform and Manipulate Data\n",
    " - Create new columns and apply functions with .apply() and vectorized operations\n",
    " - Use conditional logic for filtering and assignment\n",
    "### Subset and Filter Data\n",
    "- Select columns and rows using ```[], .loc[], .iloc[]```\n",
    "- Use .query() and boolean indexing to filter rows\n",
    "### Group and Aggregate Data\n",
    "- Group data using ```.groupby()``` and apply aggregation functions\n",
    "- Calculate summaries like mean, median, and counts by groups\n",
    "### Merge and Join Datasets\n",
    "- Combine datasets using ```merge(), concat(), and join()```\n",
    "- Understand inner, outer, left, and right joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64469a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b2a86",
   "metadata": {},
   "source": [
    "# Input Folders Setup\n",
    "In order to make learning fast, we will mostly use synthetic data for this notebook except for a few cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# MAKE SURE YOU CHANGE THE PATHS BELOW TO YOUR LOCAL SETUP\n",
    "# ==========================================================\n",
    "DIR_DATA = Path.cwd().parents[1] / \"data\"\n",
    "FIlE_EMPLOYEES = DIR_DATA / \"synthetic-data-employees.csv\"\n",
    "FILE_CUSTOMERS = DIR_DATA / \"synthetic-messy-customer-data.csv\"\n",
    "FILE_SALES = DIR_DATA / \"synthetic-sales-data.csv\"\n",
    "\n",
    "# Multiple CSV files \n",
    "DIR_MULTIPLE_CSV = DIR_DATA / \"simulated_cdrs\"\n",
    "\n",
    "# Population Density Datasets\n",
    "DIR_POPULATION_DENSITY = DIR_DATA / \"population/rw-pop-density-gridded\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9552b494",
   "metadata": {},
   "source": [
    "# Getting Help with Pandas Functions\n",
    "\n",
    "Understanding how to use functions and methods in Python—especially in pandas—requires consulting the documentation. It's essential to read the documentation to learn what each function does and what its arguments mean.\n",
    "\n",
    "In pandas, there are several convenient ways to access help:\n",
    "\n",
    "1. `help(pd.DataFrame)` – Use the built-in `help()` function to view documentation for any pandas class or function.\n",
    "2. `pd.read_csv?` or `?pd.read_csv` – In Jupyter Notebook or IPython, placing a `?` before or after a function displays its signature and docstring.\n",
    "3. `df.apply?` – If `df` is your DataFrame, you can inspect the `apply` method using the same approach.\n",
    "\n",
    "These tools are invaluable when exploring new methods or troubleshooting unexpected behavior.\n",
    "\n",
    "For more detailed and up-to-date information, refer to the official [pandas API documentation](https://pandas.pydata.org/docs/reference/index.html). It provides comprehensive explanations, examples, and parameter details for every function in the library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9100c2ec",
   "metadata": {},
   "source": [
    "**EXERCISE-0:** Getting Help on Pandas Functions\n",
    "Use the following tasks to familiarize yourself with how to explore pandas functions and understand their parameters:\n",
    "\n",
    "1. Use `help(pd.read_csv)` to read the documentation for loading CSV files.\n",
    "2. Use `df.head?` to learn how the `head()` method works.\n",
    "3. Try `help(pd.merge)` and identify what the arguments `how` and `on` do.\n",
    "4. Use `df.groupby?` to check how to group your data and what options are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aef5388",
   "metadata": {},
   "source": [
    "Pandas Core Data Structures\n",
    "========================\n",
    "### Series (1-dimensional)\n",
    "### DataFrame (2-dimensional)\n",
    "We'll focus primarily on the DataFrame data structure. However, you’re encouraged to explore how to convert between DataFrames and Series for greater flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e6e366",
   "metadata": {},
   "source": [
    "### Creating DataFrames from Python Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0a17f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas DataFrames from a dictionary\n",
    "\n",
    "# Step-1 Create a dictionary with sample data\n",
    "data = {\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"age\": [25, 30, 35],\n",
    "    \"city\": [\"New York\", \"Los Angeles\", \"Chicago\"]}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca65ed3",
   "metadata": {},
   "source": [
    "# Dataframe from a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a8b728ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = [[\"Alice\", 25, \"New York\"],\n",
    "             [\"Bob\", 30, \"Los Angeles\"],\n",
    "             [\"Charlie\", 35, \"Chicago\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e0058423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_list = pd.DataFrame(list_data, columns=[\"name\", \"age\", \"city\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c386cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: From dictionary\n",
    "students_dict = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "    'Age': [23, 22, 24, 23],\n",
    "    'Grade': ['A', 'B', 'A', 'C'],\n",
    "    'Score': [92, 85, 94, 78]\n",
    "}\n",
    "students_df = pd.DataFrame(students_dict)\n",
    "\n",
    "# Method 2: From lists\n",
    "data_lists = [\n",
    "    ['Alice', 23, 'A', 92],\n",
    "    ['Bob', 22, 'B', 85],\n",
    "    ['Charlie', 24, 'A', 94],\n",
    "    ['Diana', 23, 'C', 78]\n",
    "]\n",
    "students_df2 = pd.DataFrame(data_lists, columns=['Name', 'Age', 'Grade', 'Score'])\n",
    "\n",
    "print(\"From dictionary:\")\n",
    "print(students_df)\n",
    "print(\"\\nFrom lists:\")\n",
    "print(students_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b42af5",
   "metadata": {},
   "source": [
    "**EXERCISE-1: GETTING BACK A DICTIONARY FROM A DATAFRAME**\n",
    "- Make sure you have a Dataframe\n",
    "- Use the `to_dict()` method to convert the DataFrame back into a dictionary.\n",
    "- Use help to understand the parameters of `to_dict()` and discuss the differences between the different formats it can return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "473995a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': ['Alice', 'Bob', 'Charlie'],\n",
       " 'age': [25, 30, 35],\n",
       " 'city': ['New York', 'Los Angeles', 'Chicago']}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_list.to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8431b1",
   "metadata": {},
   "source": [
    "### Basic DataFrame Inspection\n",
    "It's important to get a high-level overview of your DataFrame—especially when it’s loaded from an external source. This first look helps you understand the structure, size, and contents of the dataset before diving into detailed analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0a58180e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   name    3 non-null      object\n",
      " 1   age     3 non-null      int64 \n",
      " 2   city    3 non-null      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 204.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_from_dict.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35102b8",
   "metadata": {},
   "source": [
    "**EXERCISE-2:** Try the following:\n",
    "1. Use `df.shape` to view the dimensions of the DataFrame.\n",
    "2. Use `df.head()` to display the first few rows of the DataFrame.\n",
    "3. Use `df.columns` to get the names of the columns.\n",
    "4. Use `df.info()` to get a concise summary of the DataFrame, including data types and non-null counts.\n",
    "5. Use `df.describe()` to get a statistical summary of the numerical columns in the DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef7fea9",
   "metadata": {},
   "source": [
    "### Understanding Indexing and Columns\n",
    "In a DataFrame, **columns** represent the variables (or features) in your dataset, while the **index** represents the row labels. The index is used to uniquely identify each row and can be either the default integer labels or a custom label like a name or ID.\n",
    "\n",
    "We wil see later that ```index``` can be use in merging sometimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "171354db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_list.index = df_from_list['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "12bba40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>23</td>\n",
       "      <td>A</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice</td>\n",
       "      <td>22</td>\n",
       "      <td>B</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>24</td>\n",
       "      <td>A</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana</td>\n",
       "      <td>23</td>\n",
       "      <td>C</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age Grade  Score\n",
       "0    Alice   23     A     92\n",
       "1    Alice   22     B     85\n",
       "2  Charlie   24     A     94\n",
       "3    Diana   23     C     78"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_dict = {\n",
    "    'Name': ['Alice', 'Alice', 'Charlie', 'Diana'],\n",
    "    'Age': [23, 22, 24, 23],\n",
    "    'Grade': ['A', 'B', 'A', 'C'],\n",
    "    'Score': [92, 85, 94, 78]\n",
    "}\n",
    "df_students = pd.DataFrame(students_dict)\n",
    "df_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "387463ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students2 = df_students\n",
    "df_students2.index = df_students['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3f14b5",
   "metadata": {},
   "source": [
    "**EXERCISE-3:** Explore Index\n",
    "- Check the current index using "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3024f8",
   "metadata": {},
   "source": [
    "# Loading Data from External Sources\n",
    "Pandas makes it easy to load data from a wide range of external sources into a common tabular format (DataFrame) for analysis. This includes traditional statistical software formats like SPSS (`.sav`), Stata (`.dta`), Excel (`.xlsx`), and more. Once loaded, all data can be handled consistently using pandas tools, regardless of the original format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "56d91aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_employees = pd.read_csv(FIlE_EMPLOYEES)\n",
    "df_employees = pd.read_csv(\"/Users/dmatekenya/My Drive (dmatekenya@gmail.com)/TEACHING/AIMS-DSCBI/data/synthetic-data-employees.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436db576",
   "metadata": {},
   "source": [
    "### Basic Column Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a212cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting single columns\n",
    "names = df_employees['name']\n",
    "print(\"Single column (Series):\")\n",
    "print(type(names))\n",
    "print(names.head())\n",
    "\n",
    "# Selecting multiple columns\n",
    "basic_info = df_employees[['name', 'department', 'salary']]\n",
    "print(\"\\nMultiple columns (DataFrame):\")\n",
    "print(type(basic_info))\n",
    "print(basic_info.head())\n",
    "\n",
    "# Different ways to select columns\n",
    "print(\"\\nDifferent selection methods:\")\n",
    "print(\"Dot notation:\", type(df_employees.name))  # Works for valid Python names\n",
    "print(\"Bracket notation:\", type(df_employees['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d540056a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      John Smith\n",
       "1        Jane Doe\n",
       "2    Mike Johnson\n",
       "3    Sarah Wilson\n",
       "4     David Brown\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = df_employees['name']\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21682f76",
   "metadata": {},
   "source": [
    "### Basic Row Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8bb08644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>department</th>\n",
       "      <th>salary</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>IT</td>\n",
       "      <td>75000</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Jane Doe</td>\n",
       "      <td>HR</td>\n",
       "      <td>65000</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Mike Johnson</td>\n",
       "      <td>Finance</td>\n",
       "      <td>70000</td>\n",
       "      <td>7</td>\n",
       "      <td>2018-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Sarah Wilson</td>\n",
       "      <td>IT</td>\n",
       "      <td>80000</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-09-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>David Brown</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>60000</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>Lisa Davis</td>\n",
       "      <td>Finance</td>\n",
       "      <td>72000</td>\n",
       "      <td>8</td>\n",
       "      <td>2019-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>Tom Miller</td>\n",
       "      <td>IT</td>\n",
       "      <td>78000</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>Amy Garcia</td>\n",
       "      <td>HR</td>\n",
       "      <td>63000</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>109</td>\n",
       "      <td>Chris Lee</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>58000</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110</td>\n",
       "      <td>Maria Rodriguez</td>\n",
       "      <td>Finance</td>\n",
       "      <td>74000</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-03-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id             name department  salary  years_experience  \\\n",
       "0          101       John Smith         IT   75000                 5   \n",
       "1          102         Jane Doe         HR   65000                 3   \n",
       "2          103     Mike Johnson    Finance   70000                 7   \n",
       "3          104     Sarah Wilson         IT   80000                 6   \n",
       "4          105      David Brown  Marketing   60000                 2   \n",
       "5          106       Lisa Davis    Finance   72000                 8   \n",
       "6          107       Tom Miller         IT   78000                 4   \n",
       "7          108       Amy Garcia         HR   63000                 3   \n",
       "8          109        Chris Lee  Marketing   58000                 1   \n",
       "9          110  Maria Rodriguez    Finance   74000                 9   \n",
       "\n",
       "    hire_date  \n",
       "0  2018-01-01  \n",
       "1  2018-04-01  \n",
       "2  2018-06-30  \n",
       "3  2018-09-28  \n",
       "4  2018-12-27  \n",
       "5  2019-03-27  \n",
       "6  2019-06-25  \n",
       "7  2019-09-23  \n",
       "8  2019-12-22  \n",
       "9  2020-03-21  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Row selection using indexing\n",
    "# df_employees[:10]\n",
    "# Row selection using loc\n",
    "df_employees.loc[:9]  # Selects rows 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a909d9",
   "metadata": {},
   "source": [
    "# ```.loc``` works with labels, not integer positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "da098621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id           106\n",
       "name           Lisa Davis\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_employees.loc[5, ['employee_id', 'name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cbdc5522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees['employee_id'] = df_employees['employee_id'].astype(str)\n",
    "df_employees2 = df_employees.set_index('employee_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d5dbf2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>department</th>\n",
       "      <th>salary</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>IT</td>\n",
       "      <td>75000</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Jane Doe</td>\n",
       "      <td>HR</td>\n",
       "      <td>65000</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Mike Johnson</td>\n",
       "      <td>Finance</td>\n",
       "      <td>70000</td>\n",
       "      <td>7</td>\n",
       "      <td>2018-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Sarah Wilson</td>\n",
       "      <td>IT</td>\n",
       "      <td>80000</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-09-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>David Brown</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>60000</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id          name department  salary  years_experience   hire_date\n",
       "0          101    John Smith         IT   75000                 5  2018-01-01\n",
       "1          102      Jane Doe         HR   65000                 3  2018-04-01\n",
       "2          103  Mike Johnson    Finance   70000                 7  2018-06-30\n",
       "3          104  Sarah Wilson         IT   80000                 6  2018-09-28\n",
       "4          105   David Brown  Marketing   60000                 2  2018-12-27"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_employees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e024274d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name          Jane Doe\n",
       "department          HR\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_employees.iloc[1, [1, 2]].head()  # Example with a specific index label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "860a6b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>department</th>\n",
       "      <th>salary</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>John Smith</td>\n",
       "      <td>IT</td>\n",
       "      <td>75000</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Rwanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Jane Doe</td>\n",
       "      <td>HR</td>\n",
       "      <td>65000</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>Rwanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Mike Johnson</td>\n",
       "      <td>Finance</td>\n",
       "      <td>70000</td>\n",
       "      <td>7</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>Malawi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Sarah Wilson</td>\n",
       "      <td>IT</td>\n",
       "      <td>80000</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-09-28</td>\n",
       "      <td>Rwanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>David Brown</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>60000</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>Rwanda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name department  salary  years_experience   hire_date  \\\n",
       "employee_id                                                                  \n",
       "101            John Smith         IT   75000                 5  2018-01-01   \n",
       "102              Jane Doe         HR   65000                 3  2018-04-01   \n",
       "103          Mike Johnson    Finance   70000                 7  2018-06-30   \n",
       "104          Sarah Wilson         IT   80000                 6  2018-09-28   \n",
       "105           David Brown  Marketing   60000                 2  2018-12-27   \n",
       "\n",
       "            country  \n",
       "employee_id          \n",
       "101          Rwanda  \n",
       "102          Rwanda  \n",
       "103          Malawi  \n",
       "104          Rwanda  \n",
       "105          Rwanda  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_employees2 = df_employees.set_index('employee_id')\n",
    "df_employees2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc971c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using .loc[] - label-based selection\n",
    "print(\"Using .loc[] - first 3 rows:\")\n",
    "print(df_employees.loc[0:2])  # Includes end index\n",
    "\n",
    "print(\"\\nUsing .loc[] - specific rows and columns:\")\n",
    "print(df_employees.loc[0:2, ['name', 'salary']])\n",
    "\n",
    "# Using .iloc[] - position-based selection\n",
    "print(\"\\nUsing .iloc[] - first 3 rows:\")\n",
    "print(df_employees.iloc[0:3])  # Excludes end index\n",
    "\n",
    "print(\"\\nUsing .iloc[] - specific positions:\")\n",
    "print(df_employees.iloc[0:3, [1, 3]])  # First 3 rows, columns 1 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809647b",
   "metadata": {},
   "source": [
    "**EXERCISE-ROW SELECTION: TRY THE FOLLOWING**\n",
    "1. SET INDEX OF DATAFRAME TO ```name``` column\n",
    "2. USE ```.iloc``` TO MAKE THIS SELECTION:\n",
    "    > EMPLOYEE NAME: 'John Smith'\n",
    "    > ```salary``` and ```department```\n",
    "3. TRY THE SAME THING USING ```.loc```\n",
    "4. WHATS HAPPENING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ca6bc3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees2 = df_employees.set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "07d33f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id    101\n",
       "department      IT\n",
       "Name: John Smith, dtype: object"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_employees2.loc['John Smith', ['employee_id', 'department']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd93314",
   "metadata": {},
   "source": [
    "# Data Selection and Filtering\n",
    "The goal here is to be able to do the following:\n",
    "- **Create** and apply boolean masks for data filtering\n",
    "- **Use** comparison operators to filter data based on conditions\n",
    "- **Combine** multiple conditions using logical operators\n",
    "- **Apply** string methods for text-based filtering\n",
    "- **Filter** DataFrames using complex conditional logic\n",
    "- **Select** specific subsets of data based on multiple criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f6f1e3",
   "metadata": {},
   "source": [
    "### Boolean Indexing Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b527860a",
   "metadata": {},
   "source": [
    "# Boolean filtering in One Liner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "cf471445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>department</th>\n",
       "      <th>salary</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>IT</td>\n",
       "      <td>75000</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Sarah Wilson</td>\n",
       "      <td>IT</td>\n",
       "      <td>80000</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-09-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>Lisa Davis</td>\n",
       "      <td>Finance</td>\n",
       "      <td>72000</td>\n",
       "      <td>8</td>\n",
       "      <td>2019-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>Tom Miller</td>\n",
       "      <td>IT</td>\n",
       "      <td>78000</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110</td>\n",
       "      <td>Maria Rodriguez</td>\n",
       "      <td>Finance</td>\n",
       "      <td>74000</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-03-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id             name department  salary  years_experience  \\\n",
       "0          101       John Smith         IT   75000                 5   \n",
       "3          104     Sarah Wilson         IT   80000                 6   \n",
       "5          106       Lisa Davis    Finance   72000                 8   \n",
       "6          107       Tom Miller         IT   78000                 4   \n",
       "9          110  Maria Rodriguez    Finance   74000                 9   \n",
       "\n",
       "    hire_date  \n",
       "0  2018-01-01  \n",
       "3  2018-09-28  \n",
       "5  2019-03-27  \n",
       "6  2019-06-25  \n",
       "9  2020-03-21  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_high_salary_employees = df_employees[df_employees['salary'] > 70000]\n",
    "df_high_salary_employees.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45508d6c",
   "metadata": {},
   "source": [
    "# Boolean filtering in Two Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_salary_mask = df_employees['salary'] > 70000\n",
    "high_salary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "330b390e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# APPLY THE MASK TO THE DATAFRAME\n",
    "df_high_salary_employees = df_employees[high_salary_mask]\n",
    "df_high_salary_employees.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c143721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating boolean masks\n",
    "high_salary_mask = df_employees['salary'] > 70000\n",
    "print(\"Boolean mask for high salary:\")\n",
    "print(high_salary_mask.head(10))\n",
    "print(f\"Mask type: {type(high_salary_mask)}\")\n",
    "\n",
    "# Applying the mask to filter data\n",
    "high_salary_employees = df_employees[high_salary_mask]\n",
    "print(f\"\\nEmployees with salary > $70,000:\")\n",
    "print(high_salary_employees[['name', 'salary', 'department']])\n",
    "print(f\"Count: {len(high_salary_employees)} out of {len(df_employees)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cfa8cd",
   "metadata": {},
   "source": [
    "### Comparison Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2de01e",
   "metadata": {},
   "source": [
    "# SELECT ALL EMPLOYEES WORKING IN IT DEPARTMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5d2d5c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "department\n",
       "IT    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_IT = df_employees[df_employees['department'] == 'IT']\n",
    "df_IT.department.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee246c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different comparison operators\n",
    "print(\"IT Department employees:\")\n",
    "it_employees = df_employees[df_employees['department'] == 'IT']\n",
    "print(it_employees[['name', 'department', 'salary']])\n",
    "\n",
    "print(\"\\nExperienced employees (>= 5 years):\")\n",
    "experienced = df_employees[df_employees['years_experience'] >= 5]\n",
    "print(experienced[['name', 'years_experience', 'salary']])\n",
    "\n",
    "print(\"\\nNot in HR department:\")\n",
    "non_hr = df_employees[df_employees['department'] != 'HR']\n",
    "print(f\"Non-HR employees: {len(non_hr)} out of {len(df_employees)}\")\n",
    "\n",
    "# Using .isin() for multiple values\n",
    "target_departments = ['IT', 'Finance']\n",
    "it_finance = df_employees[df_employees['department'].isin(target_departments)]\n",
    "print(f\"\\nIT and Finance employees: {len(it_finance)}\")\n",
    "print(it_finance[['name', 'department', 'salary']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad55e2b",
   "metadata": {},
   "source": [
    "### Filtering with the ```.query``` Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "288c4739",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees = pd.read_csv(FIlE_EMPLOYEES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4caf06",
   "metadata": {},
   "source": [
    "# FILTER FOR HIGH SALARY EMPLOYEES "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63c2f09",
   "metadata": {},
   "source": [
    "### METHOD-1: BOOLEAN MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0d2ecc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_salary_employees = df_employees[df_employees['salary'] > 70000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4455b6a8",
   "metadata": {},
   "source": [
    "### METHOD-2: ```.query```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5c240",
   "metadata": {},
   "source": [
    "### Single Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "eca6a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_salary_employees = df_employees.query('salary > 70000 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "da832eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_salary_employees = df_employees.query('salary > 70000 and department == \"IT\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using query() method for readable conditions\n",
    "high_performers = df_employees.query('salary > 70000 and years_experience >= 5')\n",
    "print(\"High performers using query():\")\n",
    "print(high_performers[['name', 'salary', 'years_experience']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c67276",
   "metadata": {},
   "source": [
    "**EXERCISE-4: EXPLORE FILTERING WITH MULTIPLE CONDITIONS**\n",
    "- Boolean Mask. create a new dataframe for employees who work in HR and receive salary higher than 50,000\n",
    "- ```.query```. Do the above using ```.query``` method\n",
    "- Report how many employees are in this new Dataframe\n",
    "- **Challenge:** Add 'years_experience' condition such as less than 5 years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eecf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More Filtering Methods\n",
    "pd.DataFrame.filter?\n",
    "pd.DataFrame.isin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fe6ece55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>department</th>\n",
       "      <th>salary</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>hire_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>IT</td>\n",
       "      <td>75000</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Jane Doe</td>\n",
       "      <td>HR</td>\n",
       "      <td>65000</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Sarah Wilson</td>\n",
       "      <td>IT</td>\n",
       "      <td>80000</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-09-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>Tom Miller</td>\n",
       "      <td>IT</td>\n",
       "      <td>78000</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>Amy Garcia</td>\n",
       "      <td>HR</td>\n",
       "      <td>63000</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>111</td>\n",
       "      <td>James Taylor</td>\n",
       "      <td>IT</td>\n",
       "      <td>82000</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>112</td>\n",
       "      <td>Linda Martinez</td>\n",
       "      <td>HR</td>\n",
       "      <td>64000</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-09-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>115</td>\n",
       "      <td>Michael Jackson</td>\n",
       "      <td>IT</td>\n",
       "      <td>79000</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>116</td>\n",
       "      <td>Jennifer White</td>\n",
       "      <td>HR</td>\n",
       "      <td>66000</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>119</td>\n",
       "      <td>Richard Lewis</td>\n",
       "      <td>IT</td>\n",
       "      <td>81000</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-06-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>120</td>\n",
       "      <td>Susan Robinson</td>\n",
       "      <td>HR</td>\n",
       "      <td>67000</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-09-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    employee_id             name department  salary  years_experience  \\\n",
       "0           101       John Smith         IT   75000                 5   \n",
       "1           102         Jane Doe         HR   65000                 3   \n",
       "3           104     Sarah Wilson         IT   80000                 6   \n",
       "6           107       Tom Miller         IT   78000                 4   \n",
       "7           108       Amy Garcia         HR   63000                 3   \n",
       "10          111     James Taylor         IT   82000                 7   \n",
       "11          112   Linda Martinez         HR   64000                 4   \n",
       "14          115  Michael Jackson         IT   79000                 5   \n",
       "15          116   Jennifer White         HR   66000                 3   \n",
       "18          119    Richard Lewis         IT   81000                 6   \n",
       "19          120   Susan Robinson         HR   67000                 4   \n",
       "\n",
       "     hire_date  \n",
       "0   2018-01-01  \n",
       "1   2018-04-01  \n",
       "3   2018-09-28  \n",
       "6   2019-06-25  \n",
       "7   2019-09-23  \n",
       "10  2020-06-19  \n",
       "11  2020-09-17  \n",
       "14  2021-06-14  \n",
       "15  2021-09-12  \n",
       "18  2022-06-09  \n",
       "19  2022-09-07  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "department = ['IT', 'HR']\n",
    "df_employees[df_employees['department'].isin(department)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a6abf4",
   "metadata": {},
   "source": [
    "# Data Cleaning Basics with Pandas\n",
    "The goal is to be able to do some of the following:\n",
    "- **Identify** and handle missing data using various strategies\n",
    "- **Detect** and remove duplicate records from DataFrames\n",
    "- **Convert** data types appropriately for analysis\n",
    "- **Rename** columns for better readability and consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1b6e6313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messy = pd.read_csv(\"/Users/dmatekenya/My Drive (dmatekenya@gmail.com)/TEACHING/AIMS-DSCBI/data/synthetic-messy-customer-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e363c023",
   "metadata": {},
   "source": [
    "### Identifying and Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a5a0bf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_messy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d99623f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Customer_ID      10 non-null     int64  \n",
      " 1   customer name    8 non-null      object \n",
      " 2   age              9 non-null      float64\n",
      " 3   email            9 non-null      object \n",
      " 4   purchase_amount  10 non-null     object \n",
      " 5   signup_date      9 non-null      object \n",
      " 6   status           10 non-null     object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 692.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_messy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99efc68c",
   "metadata": {},
   "source": [
    "# GET TOTAL NUM OF MISSING VALEUS IN A COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "76415672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_messy['customer name'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "931209d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = {'customer name': 'customer_name'}\n",
    "df_messy.rename(columns=new_columns, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26383d",
   "metadata": {},
   "source": [
    "# OTHER METHODS DEALING WITH MISSING VALIUES:\n",
    ">DataFrame.isnull : Alias of isna.\n",
    "\n",
    ">DataFrame.notna : Boolean inverse of isna.\n",
    "\n",
    ">DataFrame.dropna : Omit axes labels with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3424d8e5",
   "metadata": {},
   "source": [
    "# DROPPING NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "69980605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messy2 = df_messy.dropna(subset=['customer_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40585f9e",
   "metadata": {},
   "source": [
    "# DROP ROWS IF THERE IS NULL IN ANY COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c10c8ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Customer_ID      6 non-null      int64  \n",
      " 1   customer_name    6 non-null      object \n",
      " 2   age              6 non-null      float64\n",
      " 3   email            6 non-null      object \n",
      " 4   purchase_amount  6 non-null      object \n",
      " 5   signup_date      6 non-null      object \n",
      " 6   status           6 non-null      object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 384.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_messy_not_null.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c3d65b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Customer_ID      10 non-null     int64  \n",
      " 1   customer_name    8 non-null      object \n",
      " 2   age              9 non-null      float64\n",
      " 3   email            9 non-null      object \n",
      " 4   purchase_amount  10 non-null     object \n",
      " 5   signup_date      9 non-null      object \n",
      " 6   status           10 non-null     object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 692.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_messy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "688a10e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer_ID          int64\n",
       "customer_name       object\n",
       "age                float64\n",
       "email               object\n",
       "purchase_amount     object\n",
       "signup_date         object\n",
       "status              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_messy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2a4a3952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messy.customer_name.fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "4ab81ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original missing values:\n",
      "2 10\n",
      "Original non-missing values:\n",
      "0 8\n"
     ]
    }
   ],
   "source": [
    "print('Original missing values:')\n",
    "print(df_messy.customer_name.isnull().sum(), df_messy.shape[0])\n",
    "\n",
    "print('Original non-missing values:')\n",
    "print(df_messy2.customer_name.isnull().sum(), df_messy2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69ff7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df_messy.isnull().sum())\n",
    "\n",
    "print(\"\\nPercentage of missing values:\")\n",
    "missing_percentages = (df_messy.isnull().sum() / len(df_messy) * 100).round(2)\n",
    "print(missing_percentages)\n",
    "\n",
    "# Visualize missing data pattern\n",
    "print(\"\\nMissing data pattern:\")\n",
    "print(df_messy.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9091a2",
   "metadata": {},
   "source": [
    "### Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "2544251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messy['income'] = \"90000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "fe9a8f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messy[\"income_num\"]  = df_messy['income'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce54f650",
   "metadata": {},
   "source": [
    "# CONVERT STRING TIME TO PYTHON TIME OBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "51c3c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert signup_date to datetime\n",
    "df_messy['signup_date_ts'] = pd.to_datetime(df_messy['signup_date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "e77091e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Data Type: <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "Original Data Type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print('Modified Data Type:', type(df_messy['signup_date_ts'].iloc[0]))\n",
    "print(\"Original Data Type:\", type(df_messy['signup_date'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a250fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current data types\n",
    "print(\"Current data types:\")\n",
    "print(df_messy.dtypes)\n",
    "\n",
    "# Convert data types\n",
    "df_typed = df_messy.copy()\n",
    "\n",
    "# Convert purchase_amount to numeric (handling invalid values)\n",
    "df_typed['purchase_amount'] = pd.to_numeric(df_typed['purchase_amount'], errors='coerce')\n",
    "\n",
    "# Convert signup_date to datetime\n",
    "df_typed['signup_date'] = pd.to_datetime(df_typed['signup_date'], errors='coerce')\n",
    "\n",
    "# Convert Customer_ID to integer (after handling missing values)\n",
    "df_typed['Customer_ID'] = df_typed['Customer_ID'].astype('int64')\n",
    "\n",
    "# Convert status to category for memory efficiency\n",
    "df_typed['status'] = df_typed['status'].astype('category')\n",
    "\n",
    "print(\"\\nAfter type conversion:\")\n",
    "print(df_typed.dtypes)\n",
    "\n",
    "# Show the cleaned numeric column\n",
    "print(\"\\nCleaned purchase amounts:\")\n",
    "print(df_typed[['Customer_ID', 'purchase_amount']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c25909",
   "metadata": {},
   "source": [
    "**EXERCISES-5:** Detecting Duplicates and Renaming Columns\n",
    "- Explore pndas duplicated method to identify duplicate rows in a DataFrame.\n",
    "- Use the `drop_duplicates()` method to remove duplicates.\n",
    "- Next rename columns to something you like "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e65a10",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de78c5",
   "metadata": {},
   "source": [
    "### Creating New Columns with Calculations\n",
    "\n",
    "When creating new columns based on existing data, you're often performing operations row by row. The `.apply()` function in pandas is a powerful and efficient way to do this. It allows you to apply a custom function across rows or columns, making it ideal for generating new variables based on specific logic or transformations.\n",
    "\n",
    "While it's possible to loop through DataFrame rows manually using `.iterrows()`, this approach is generally slower and less efficient. The recommended method is to use `.apply()` in one of the following ways:\n",
    "\n",
    "- **Lambda functions** – For simple, one-line conditions or calculations, use an in-line lambda function with `.apply()`.\n",
    "- **Custom functions** – For more complex logic or multi-step conditions, define a separate function and pass it to `.apply()`.\n",
    "\n",
    "This method not only makes your code cleaner and more readable but also improves performance in most cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "98190f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.read_csv(FILE_SALES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbfadcd",
   "metadata": {},
   "source": [
    "# ADD COLUMN WITH SIMPLE CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "cdc2c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['total'] = df_sales['unit_price'] * df_sales['quantity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed7abb",
   "metadata": {},
   "source": [
    "# ADDING A COLUMN WITH COMPLICATED LOGIC\n",
    "```total = X + 2*unit_price, where X=10```\n",
    "\n",
    "```total = X + 2*unit_price + unit_price*quantity```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "80026ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_complicated_total(row):\n",
    "    output = 10 + 2 * row['unit_price'] + row['unit_price'] * row['quantity']\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['total_complicated'] = df_sales.apply(add_complicated_total, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "c3788c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['total_comp1'] = df_sales.apply(lambda row: 10+ 2*row['unit_price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "dbbbd7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_comp1</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>821.62</td>\n",
       "      <td>405.81</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1916.36</td>\n",
       "      <td>953.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500.78</td>\n",
       "      <td>745.39</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1247.46</td>\n",
       "      <td>618.73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>406.44</td>\n",
       "      <td>198.22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_comp1  unit_price  quantity\n",
       "0       821.62      405.81         7\n",
       "1      1916.36      953.18         1\n",
       "2      1500.78      745.39         4\n",
       "3      1247.46      618.73         4\n",
       "4       406.44      198.22         5"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales[['total_comp1', 'unit_price', 'quantity']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "e04b8a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2840.67</td>\n",
       "      <td>405.81</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>953.18</td>\n",
       "      <td>953.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2981.56</td>\n",
       "      <td>745.39</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2474.92</td>\n",
       "      <td>618.73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>991.10</td>\n",
       "      <td>198.22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     total  unit_price  quantity\n",
       "0  2840.67      405.81         7\n",
       "1   953.18      953.18         1\n",
       "2  2981.56      745.39         4\n",
       "3  2474.92      618.73         4\n",
       "4   991.10      198.22         5"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales[['total', 'unit_price', 'quantity']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic mathematical operations\n",
    "df_sales['total_amount'] = df_sales['unit_price'] * df_sales['quantity']\n",
    "df_sales['discount_5_percent'] = df_sales['total_amount'] * 0.05\n",
    "df_sales['final_amount'] = df_sales['total_amount'] - df_sales['discount_5_percent']\n",
    "\n",
    "print(\"New calculated columns:\")\n",
    "print(df_sales[['unit_price', 'quantity', 'total_amount', 'final_amount']].head())\n",
    "\n",
    "# Conditional calculations\n",
    "df_sales['order_size'] = df_sales['quantity'].apply(\n",
    "    lambda x: 'Large' if x >= 7 else 'Medium' if x >= 4 else 'Small'\n",
    ")\n",
    "\n",
    "# Using np.where for conditional logic\n",
    "df_sales['price_category'] = np.where(\n",
    "    df_sales['unit_price'] >= 500, 'Premium',\n",
    "    np.where(df_sales['unit_price'] >= 200, 'Standard', 'Budget')\n",
    ")\n",
    "\n",
    "print(\"\\nConditional columns:\")\n",
    "print(df_sales[['quantity', 'order_size', 'unit_price', 'price_category']].head(10))\n",
    "\n",
    "# Multiple conditions with np.select\n",
    "conditions = [\n",
    "    (df_sales['total_amount'] >= 1000) & (df_sales['quantity'] >= 5),\n",
    "    (df_sales['total_amount'] >= 500) & (df_sales['quantity'] >= 3),\n",
    "    df_sales['total_amount'] >= 200\n",
    "]\n",
    "choices = ['VIP Order', 'Standard Order', 'Regular Order']\n",
    "df_sales['order_type'] = np.select(conditions, choices, default='Small Order')\n",
    "\n",
    "print(\"\\nOrder type classification:\")\n",
    "print(df_sales[['total_amount', 'quantity', 'order_type']].value_counts('order_type'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc311db",
   "metadata": {},
   "source": [
    "### Using Apply() for Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c3924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shipping_cost(row):\n",
    "    \"\"\"Calculate shipping cost based on order value and quantity\"\"\"\n",
    "    base_cost = 10\n",
    "    if row['total_amount'] > 500:\n",
    "        return 0  # Free shipping for orders over $500\n",
    "    elif row['quantity'] > 5:\n",
    "        return base_cost * 0.5  # 50% discount for bulk orders\n",
    "    else:\n",
    "        return base_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56366273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple apply with lambda\n",
    "df_sales['price_per_letter'] = df_sales.apply(\n",
    "    lambda row: row['unit_price'] / len(row['product_name']), axis=1\n",
    ")\n",
    "\n",
    "# Custom function for complex logic\n",
    "df_sales['shipping_cost'] = df_sales.apply(calculate_shipping_cost, axis=1)\n",
    "\n",
    "print(\"Custom calculations with apply:\")\n",
    "print(df_sales[['total_amount', 'quantity', 'shipping_cost']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5fd315",
   "metadata": {},
   "source": [
    "# Grouping and Aggregation\n",
    "The goal is to understand groupby basics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac24413",
   "metadata": {},
   "source": [
    "### Understanding GroupBy Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c487f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The split-apply-combine concept\n",
    "print(\"Understanding GroupBy:\")\n",
    "\n",
    "# Simple grouping by one column\n",
    "category_groups = sales_df.groupby('category')\n",
    "print(f\"Number of groups: {category_groups.ngroups}\")\n",
    "print(f\"Group sizes: {category_groups.size()}\")\n",
    "\n",
    "# Basic aggregation\n",
    "category_sales = sales_df.groupby('category')['total_amount'].sum()\n",
    "print(\"\\nTotal sales by category:\")\n",
    "print(category_sales)\n",
    "\n",
    "# Multiple aggregations\n",
    "category_stats = sales_df.groupby('category')['total_amount'].agg(['sum', 'mean', 'count', 'std'])\n",
    "print(\"\\nCategory statistics:\")\n",
    "print(category_stats.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23abf14",
   "metadata": {},
   "source": [
    "### Single Column Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5bd541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single column grouping with multiple aggregations\n",
    "# The split-apply-combine concept\n",
    "print(\"Understanding GroupBy:\")\n",
    "\n",
    "# Simple grouping by one column\n",
    "category_groups = df_sales.groupby('category')\n",
    "print(f\"Number of groups: {category_groups.ngroups}\")\n",
    "print(f\"Group sizes: {category_groups.size()}\")\n",
    "\n",
    "# Basic aggregation\n",
    "category_sales = df_sales.groupby('category')['total_amount'].sum()\n",
    "print(\"\\nTotal sales by category:\")\n",
    "print(category_sales)\n",
    "\n",
    "# Multiple aggregations\n",
    "category_stats = df_sales.groupby('category')['total_amount'].agg(['sum', 'mean', 'count', 'std'])\n",
    "print(\"\\nCategory statistics:\")\n",
    "print(category_stats.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67062889",
   "metadata": {},
   "source": [
    "# Combining Datasets in Pandas\n",
    "\n",
    "In real-world data analysis, it's common to work with data spread across multiple tables or files. Pandas provides powerful tools to combine these datasets efficiently:\n",
    "\n",
    "##  Concatenation (`pd.concat`)\n",
    "- **What it does**: Stacks DataFrames either vertically (row-wise) or horizontally (column-wise).\n",
    "- **When to use**: When the datasets have the same structure (e.g., same columns for vertical stacking).\n",
    "- **Example**: Combining monthly sales reports stored as separate DataFrames into one long DataFrame.\n",
    "\n",
    "\n",
    "## Merge (`pd.merge`)\n",
    "- **What it does**: Combines DataFrames based on one or more common columns (similar to SQL joins).\n",
    "- **When to use**: When you need to enrich one dataset with columns from another based on shared keys (e.g., customer ID, district).\n",
    "- **Types of joins**:\n",
    "  - `inner` – Only rows with matching keys in both DataFrames\n",
    "  - `left` – All rows from the left DataFrame, with matches from the right\n",
    "  - `right` – All rows from the right DataFrame, with matches from the left\n",
    "  - `outer` – All rows from both, matching where possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38943cd",
   "metadata": {},
   "source": [
    "### Concatenating Multiple DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cbff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading multiple CSV files into a list using ```glob```\n",
    "csv_files = [f for f in DIR_MULTIPLE_CSV.glob(\"*.csv\")]\n",
    "\n",
    "# Read the first 5 CSV files\n",
    "dfs = [pd.read_csv(file) for file in csv_files[:5]]\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "df_combined = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c59a2",
   "metadata": {},
   "source": [
    "**EXERCISES-6:** What conditions do you think are important for concatenating multiple DataFrames? \n",
    "Consider aspects like column consistency, data types, and handling of missing values. How would you ensure that the combined DataFrame maintains data integrity and usability for further analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9987cb33",
   "metadata": {},
   "source": [
    "### Merging DataFrames\n",
    "To quickly grasp how merging works, we’ll use a simple, AI-generated synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d838998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_customer_datasets():\n",
    "    \"\"\"Create related customer datasets for merge examples\"\"\"\n",
    "    \n",
    "    # Customer basic info\n",
    "    customers = pd.DataFrame({\n",
    "        'customer_id': [101, 102, 103, 104, 105],\n",
    "        'name': ['Alice Johnson', 'Bob Smith', 'Carol Brown', 'David Wilson', 'Eve Davis'],\n",
    "        'email': ['alice@email.com', 'bob@email.com', 'carol@email.com', 'david@email.com', 'eve@email.com'],\n",
    "        'city': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n",
    "        'signup_date': pd.date_range('2023-01-01', periods=5, freq='30D')\n",
    "    })\n",
    "    \n",
    "    # Orders data (includes some customers not in customers table)\n",
    "    orders = pd.DataFrame({\n",
    "        'order_id': range(1001, 1013),\n",
    "        'customer_id': [101, 102, 101, 103, 104, 102, 105, 106, 103, 107, 101, 104],\n",
    "        'product_name': ['Laptop', 'Phone', 'Tablet', 'Monitor', 'Keyboard', 'Mouse', \n",
    "                        'Headphones', 'Speaker', 'Webcam', 'Microphone', 'Charger', 'Cable'],\n",
    "        'amount': [999, 699, 399, 299, 49, 25, 149, 199, 79, 89, 39, 15],\n",
    "        'order_date': pd.date_range('2023-02-01', periods=12, freq='5D')\n",
    "    })\n",
    "    \n",
    "    # Customer preferences\n",
    "    preferences = pd.DataFrame({\n",
    "        'customer_id': [101, 102, 103, 104, 108],  # Note: 108 not in customers\n",
    "        'preferred_category': ['Electronics', 'Electronics', 'Accessories', 'Electronics', 'Books'],\n",
    "        'communication_preference': ['Email', 'SMS', 'Email', 'Phone', 'Email'],\n",
    "        'loyalty_tier': ['Gold', 'Silver', 'Bronze', 'Gold', 'Silver']\n",
    "    })\n",
    "    \n",
    "    # Product categories\n",
    "    products = pd.DataFrame({\n",
    "        'product_name': ['Laptop', 'Phone', 'Tablet', 'Monitor', 'Keyboard', 'Mouse', \n",
    "                        'Headphones', 'Speaker', 'Webcam', 'Microphone'],\n",
    "        'category': ['Electronics', 'Electronics', 'Electronics', 'Electronics', \n",
    "                    'Accessories', 'Accessories', 'Audio', 'Audio', 'Electronics', 'Audio'],\n",
    "        'unit_cost': [500, 300, 200, 150, 20, 10, 75, 100, 40, 45],\n",
    "        'supplier': ['TechCorp', 'PhoneCo', 'TabletInc', 'DisplayTech', 'KeyMaker', \n",
    "                    'ClickCorp', 'AudioPro', 'SoundTech', 'VisionCorp', 'AudioPro']\n",
    "    })\n",
    "    \n",
    "    return customers, orders, preferences, products\n",
    "\n",
    "customers, orders, preferences, products = create_customer_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb7874",
   "metadata": {},
   "source": [
    "### Basic Merge Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5e077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join (only matching records)\n",
    "inner_merge = pd.merge(customers, orders, on='customer_id', how='inner')\n",
    "print(\"Inner merge (customers with orders):\")\n",
    "print(inner_merge[['name', 'customer_id', 'order_id', 'product_name', 'amount']].head(10))\n",
    "print(f\"Records: {len(inner_merge)}\")\n",
    "\n",
    "# Left join (all customers, matching orders)\n",
    "left_merge = pd.merge(customers, orders, on='customer_id', how='left')\n",
    "print(\"\\nLeft merge (all customers):\")\n",
    "print(left_merge[['name', 'customer_id', 'order_id', 'product_name', 'amount']].head(10))\n",
    "print(f\"Records: {len(left_merge)}\")\n",
    "\n",
    "# Right join (all orders, matching customers)\n",
    "right_merge = pd.merge(customers, orders, on='customer_id', how='right')\n",
    "print(\"\\nRight merge (all orders):\")\n",
    "print(right_merge[['name', 'customer_id', 'order_id', 'product_name', 'amount']].head(10))\n",
    "print(f\"Records: {len(right_merge)}\")\n",
    "\n",
    "# Outer join (all records from both tables)\n",
    "outer_merge = pd.merge(customers, orders, on='customer_id', how='outer')\n",
    "print(\"\\nOuter merge (all customers and orders):\")\n",
    "print(outer_merge[['name', 'customer_id', 'order_id', 'product_name', 'amount']].head(15))\n",
    "print(f\"Records: {len(outer_merge)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bd7a1e",
   "metadata": {},
   "source": [
    "**EXERCISE-7:** Merging Population Density Datasets [rw-pop-density-gridded]\n",
    "\n",
    "We have multiple CSV files all with information about population density. Please use the strategy below to merge all of them.\n",
    "\n",
    "- Create a list of csv files using ```glob```. You can read up briefly on how ```glob``` works.\n",
    "- Load each CSV file into Pandas Dataframe\n",
    "- Create a new column ```lat_lon``` to hold unique identifier \n",
    "- Check number of unique observations in each dataframe\n",
    "- merge dataframes using the created ```lat_lon``` column\n",
    "- Check that all rows merged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e4a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [f for f in DIR_POPULATION_DENSITY.glob(\"*.csv\")]\n",
    "print(f\"Found {len(csv_files)} population density CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7944ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_files[0])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f8035",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Convert latitude and longitude to string\n",
    "    df['latitude'] = df['latitude'].astype(str)\n",
    "    df['longitude'] = df['longitude'].astype(str)\n",
    "\n",
    "    df['lat_lon'] = df['latitude'] + '_' + df['longitude']\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e5cfbb",
   "metadata": {},
   "source": [
    "## Lets merge the first two for practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998327db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Dataframe to use as base for merging\n",
    "df1 = df_list[0]\n",
    "df2 = df_list[1]\n",
    "\n",
    "print(df1.shape, df2.shape)\n",
    "\n",
    "df = df1.merge(df2, on='lat_lon', how='inner', indicator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d5464e",
   "metadata": {},
   "source": [
    "# EXTENDED EXERCISE: Processing Excel File\n",
    "\n",
    "### About the Dataset\n",
    "\n",
    "The Excel file was generated by combining multiple CSV files, each containing data on different health indicators for Rwanda, such as:\n",
    "\n",
    "- `access-to-health-care_subnational_rwa`\n",
    "- `child-mortality-rates_subnational_rwa`\n",
    "- `dhs-mobile_subnational_rwa`\n",
    "\n",
    "Dataset Filename: Download the dataset from [here](https://docs.google.com/spreadsheets/d/1uvTQYS22VfXXo1Hwkm1frFx_bKkLQkcf/edit?usp=sharing&ouid=113302179168925233984&rtpof=true&sd=true).\n",
    "\n",
    "### Task-0: Explore Data in Excel\n",
    "- Take time to explore the Excel sheets and locate where each variable of interest is stored. If anything is unclear, don't hesitate to ask the tutors for clarification on the data source.\n",
    "- Ensure you identify the column that holds the indicator values so that you extract only the relevant data.\n",
    "- In most cases, the actual indicator values can be found in the column labeled `value`.\n",
    "- Additionally, be sure to retain the following important columns: `ISO3`, `Location`, and `SurveyId`.\n",
    "\n",
    "\n",
    "\n",
    "### Task-1: Generate National-Level Summaries\n",
    "\n",
    "For each indicator, your goal is to compute a single national-level value. Depending on the nature of the indicator, you may use aggregation functions such as **mean**, **median**, or **sum**.\n",
    "\n",
    "The final output should be a dataframe printed in Jupyter Notebook as well as a saved CSV file with the following columns:\n",
    "\n",
    "- `indicator_name`: The name of the indicator  \n",
    "- `value`: The aggregated national value. You may name this column based on your chosen aggregation method, e.g., `mean_indicator_name` or `median_indicator_name`.\n",
    "\n",
    "\n",
    "### Task 2: Subnational Level Indicator Dataset\n",
    "\n",
    "For indicators with subnational (administrative level 2 or 3) data available, lets merge them and a create a dataset with all those available indicators. The output dataset should have the following columns:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f97ea58",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
